{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cv2-jupyter-termux-good.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "hd4HA1_aZQVJ",
        "colab_type": "code",
        "outputId": "0b6d46af-7ca9-4eb9-fddf-a400794ee9d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        }
      },
      "cell_type": "code",
      "source": [
        "!apt install libavdevice-dev libavfilter-dev libopus-dev libvpx-dev pkg-config \n",
        "#!pip install aiohttp aiortc opencv-python websockets"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "pkg-config is already the newest version (0.29.1-0ubuntu2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  libavdevice-dev libavfilter-dev libopus-dev libpostproc-dev libvpx-dev\n",
            "0 upgraded, 5 newly installed, 0 to remove and 10 not upgraded.\n",
            "Need to get 2,286 kB of archives.\n",
            "After this operation, 9,737 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libpostproc-dev amd64 7:3.4.4-0ubuntu0.18.04.1 [51.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavfilter-dev amd64 7:3.4.4-0ubuntu0.18.04.1 [1,017 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavdevice-dev amd64 7:3.4.4-0ubuntu0.18.04.1 [87.1 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libopus-dev amd64 1.1.2-1ubuntu1 [197 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libvpx-dev amd64 1.7.0-3 [934 kB]\n",
            "Fetched 2,286 kB in 2s (1,154 kB/s)\n",
            "Selecting previously unselected package libpostproc-dev:amd64.\n",
            "(Reading database ... 131323 files and directories currently installed.)\n",
            "Preparing to unpack .../libpostproc-dev_7%3a3.4.4-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libpostproc-dev:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libavfilter-dev:amd64.\n",
            "Preparing to unpack .../libavfilter-dev_7%3a3.4.4-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libavfilter-dev:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libavdevice-dev:amd64.\n",
            "Preparing to unpack .../libavdevice-dev_7%3a3.4.4-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libavdevice-dev:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libopus-dev:amd64.\n",
            "Preparing to unpack .../libopus-dev_1.1.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking libopus-dev:amd64 (1.1.2-1ubuntu1) ...\n",
            "Selecting previously unselected package libvpx-dev:amd64.\n",
            "Preparing to unpack .../libvpx-dev_1.7.0-3_amd64.deb ...\n",
            "Unpacking libvpx-dev:amd64 (1.7.0-3) ...\n",
            "Setting up libpostproc-dev:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Setting up libavfilter-dev:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Setting up libvpx-dev:amd64 (1.7.0-3) ...\n",
            "Setting up libopus-dev:amd64 (1.1.2-1ubuntu1) ...\n",
            "Setting up libavdevice-dev:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "En-2xWFZZQVU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_p1M6XVNZQVX",
        "colab_type": "code",
        "outputId": "9c857505-f688-4079-ebe2-9bbbced6d0c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1261
        }
      },
      "cell_type": "code",
      "source": [
        "#!apt install libavdevice-dev libavfilter-dev libopus-dev libvpx-dev pkg-config\n",
        "!pip install aiohttp aiortc opencv-python dlib websockets pafy youtube-dl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting aiohttp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0d/5c/f87987f4dc8b2cfcf37c83a814ea4b2aff4d285cbffc0ab08b2b4fa3f584/aiohttp-3.5.4-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.2MB 13.3MB/s \n",
            "\u001b[?25hCollecting aiortc\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/39/54b15136368ea65d97753155c3a654fd088afd7ec6f084c043a4f75cbb99/aiortc-0.9.20.tar.gz (1.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.1MB 20.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (3.4.5.20)\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.6/dist-packages (19.16.0)\n",
            "Collecting websockets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/71/8bfa882b9c502c36e5c9ef6732969533670d2b039cbf95a82ced8f762b80/websockets-7.0-cp36-cp36m-manylinux1_x86_64.whl (63kB)\n",
            "\u001b[K    100% |████████████████████████████████| 71kB 23.4MB/s \n",
            "\u001b[?25hCollecting pafy\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/e8/3516f761558525b00d3eaf73744eed5c267db20650b7b660674547e3e506/pafy-0.5.4-py2.py3-none-any.whl\n",
            "Collecting youtube-dl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/19/ce240e0dd775f0861db51c36a293c8b24d5a66a639e7836601ec0640ec18/youtube_dl-2019.3.18-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.8MB 4.2MB/s \n",
            "\u001b[?25hCollecting typing-extensions>=3.6.5; python_version < \"3.7\" (from aiohttp)\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/62/c66e553258c37c33f9939abb2dd8d2481803d860ff68e635466f12aa7efa/typing_extensions-3.7.2-py3-none-any.whl\n",
            "Collecting idna-ssl>=1.0; python_version < \"3.7\" (from aiohttp)\n",
            "  Downloading https://files.pythonhosted.org/packages/46/03/07c4894aae38b0de52b52586b24bf189bb83e4ddabfe2e2c8f2419eec6f4/idna-ssl-1.1.0.tar.gz\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp) (19.1.0)\n",
            "Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp) (3.0.4)\n",
            "Collecting async-timeout<4.0,>=3.0 (from aiohttp)\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting multidict<5.0,>=4.0 (from aiohttp)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/cc/ceb5b8c76e7a23212b9e0353053cc35a9d86c763d852a76d9b941fe81fbc/multidict-4.5.2-cp36-cp36m-manylinux1_x86_64.whl (309kB)\n",
            "\u001b[K    100% |████████████████████████████████| 317kB 30.5MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/c0/9a73968a9f4e4dac8dffb0ba35f932dd7798fe97901f4942c2d38667862c/yarl-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (251kB)\n",
            "\u001b[K    100% |████████████████████████████████| 256kB 18.8MB/s \n",
            "\u001b[?25hCollecting aioice<0.7.0,>=0.6.13 (from aiortc)\n",
            "  Downloading https://files.pythonhosted.org/packages/03/da/f8f8464d12871bdf7ae4de4387a53c47802ea47a8c292e570d5daded31a9/aioice-0.6.14-py3-none-any.whl\n",
            "Collecting av<7.0.0,>=6.1.0 (from aiortc)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/e4/205b787753d25da5d927b59b7cf59c0b7563e3d18f35d228101658792c05/av-6.1.2.tar.gz (2.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.1MB 11.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from aiortc) (1.12.2)\n",
            "Collecting crc32c (from aiortc)\n",
            "  Downloading https://files.pythonhosted.org/packages/65/7f/4b4dc07c8fdd391c5bdf2e91d495bcfe9d8976ce7deb3439c6007c9c3625/crc32c-1.7-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting cryptography>=2.2 (from aiortc)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/12/b0409a94dad366d98a8eee2a77678c7a73aafd8c0e4b835abea634ea3896/cryptography-2.6.1-cp34-abi3-manylinux1_x86_64.whl (2.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.3MB 12.2MB/s \n",
            "\u001b[?25hCollecting pyee (from aiortc)\n",
            "  Downloading https://files.pythonhosted.org/packages/8e/06/10c18578e2d8b9cf9902f424f86d433c647ca55e82293100f53e6c0afab4/pyee-5.0.0-py2.py3-none-any.whl\n",
            "Collecting pylibsrtp>=0.5.6 (from aiortc)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/38/e27a9a8c5a643b2497612ff9d160a645034d82ac42c36c413bcf64acde81/pylibsrtp-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (64kB)\n",
            "\u001b[K    100% |████████████████████████████████| 71kB 24.5MB/s \n",
            "\u001b[?25hCollecting pyopenssl (from aiortc)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/c8/ceb170d81bd3941cbeb9940fc6cc2ef2ca4288d0ca8929ea4db5905d904d/pyOpenSSL-19.0.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 23.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.14.6)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.6/dist-packages (from idna-ssl>=1.0; python_version < \"3.7\"->aiohttp) (2.6)\n",
            "Collecting netifaces (from aioice<0.7.0,>=0.6.13->aiortc)\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/9b/c4c7eb09189548d45939a3d3a6b3d53979c67d124459b27a094c365c347f/netifaces-0.10.9-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0.0->aiortc) (2.19)\n",
            "Collecting asn1crypto>=0.21.0 (from cryptography>=2.2->aiortc)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/cd/35485615f45f30a510576f1a56d1e0a7ad7bd8ab5ed7cdc600ef7cd06222/asn1crypto-0.24.0-py2.py3-none-any.whl (101kB)\n",
            "\u001b[K    100% |████████████████████████████████| 102kB 30.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.2->aiortc) (1.11.0)\n",
            "Building wheels for collected packages: aiortc, idna-ssl, av\n",
            "  Building wheel for aiortc (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/31/66/63/07a2e95114a15113883d111c968b80d0ddbc5fa28ba759655b\n",
            "  Building wheel for idna-ssl (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d3/00/b3/32d613e19e08a739751dd6bf998cfed277728f8b2127ad4eb7\n",
            "  Building wheel for av (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/74/66/8a/bc8c189f83ec00ab76c546422bb40e363622201c3bbbc9615f\n",
            "Successfully built aiortc idna-ssl av\n",
            "Installing collected packages: typing-extensions, idna-ssl, async-timeout, multidict, yarl, aiohttp, netifaces, aioice, av, crc32c, asn1crypto, cryptography, pyee, pylibsrtp, pyopenssl, aiortc, websockets, pafy, youtube-dl\n",
            "Successfully installed aiohttp-3.5.4 aioice-0.6.14 aiortc-0.9.20 asn1crypto-0.24.0 async-timeout-3.0.1 av-6.1.2 crc32c-1.7 cryptography-2.6.1 idna-ssl-1.1.0 multidict-4.5.2 netifaces-0.10.9 pafy-0.5.4 pyee-5.0.0 pylibsrtp-0.6.1 pyopenssl-19.0.0 typing-extensions-3.7.2 websockets-7.0 yarl-1.3.0 youtube-dl-2019.3.18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "51QY21HvFH5R",
        "colab_type": "code",
        "outputId": "d8b99401-bd40-429d-a424-d9209d9aa294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://github.com/AKSHAYUBHAT/TensorFace/raw/master/openface/models/dlib/shape_predictor_68_face_landmarks.dat"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-25 04:03:25--  https://github.com/AKSHAYUBHAT/TensorFace/raw/master/openface/models/dlib/shape_predictor_68_face_landmarks.dat\n",
            "Resolving github.com (github.com)... 192.30.255.113, 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/AKSHAYUBHAT/TensorFace/master/openface/models/dlib/shape_predictor_68_face_landmarks.dat [following]\n",
            "--2019-03-25 04:03:25--  https://raw.githubusercontent.com/AKSHAYUBHAT/TensorFace/master/openface/models/dlib/shape_predictor_68_face_landmarks.dat\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 99693937 (95M) [application/octet-stream]\n",
            "Saving to: ‘shape_predictor_68_face_landmarks.dat’\n",
            "\n",
            "\r          shape_pre   0%[                    ]       0  --.-KB/s               \r         shape_pred  24%[===>                ]  23.74M   118MB/s               \r        shape_predi  48%[========>           ]  46.45M   116MB/s               \r       shape_predic  74%[=============>      ]  71.08M   118MB/s               \rshape_predictor_68_ 100%[===================>]  95.08M   119MB/s    in 0.8s    \n",
            "\n",
            "2019-03-25 04:03:27 (119 MB/s) - ‘shape_predictor_68_face_landmarks.dat’ saved [99693937/99693937]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "85za2H0FwAaP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def drawSIFT(image):\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  #Create SIFT Feature Detector object \n",
        "  #sift = cv2.SIFT() \n",
        "  sift = cv2.xfeatures2d.SIFT_create() \n",
        "  (keypoints, descs) = sift.detectAndCompute(gray, None) \n",
        "  #Detect key points #\n",
        "  keypoints = sift.detect(gray, None) \n",
        "  #print(\"Number of keypoints Detected: \", len(keypoints)) \n",
        "  # Draw rich key points on input image \n",
        "  image = cv2.drawKeypoints(image, keypoints, 0,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "  return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wl1dIqsl3XuR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def drawFAST(image):\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
        "  # Create FAST Detector object \n",
        "  fast = cv2.FastFeatureDetector_create() \n",
        "  # Obtain Key points, by default non max suppression is On \n",
        "  # to turn off set fast.setBool('nonmaxSuppression', False) \n",
        "  keypoints = fast.detect(gray, None) \n",
        "  #print (\"Number of keypoints Detected: \", len(keypoints)) \n",
        "  # Draw rich keypoints on input image \n",
        "  image = cv2.drawKeypoints(image, keypoints,0, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "  return keypoints, image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rLM6qAbv7zyF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def drawDenseOpticalFlow(previous_grey,next,hsv):\n",
        "\n",
        "    # Computes the dense optical flow using the Gunnar Farneback’s algorithm\n",
        "    flow = cv2.calcOpticalFlowFarneback(previous_grey, next, \n",
        "                                        None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "    # use flow to calculate the magnitude (speed) and angle of motion\n",
        "    # use these values to calculate the color to reflect speed and angle\n",
        "    magnitude, angle = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
        "    hsv[...,0] = angle * (180 / (np.pi/2))\n",
        "    hsv[...,2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    final = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "    \n",
        "    return next,final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V8IOHr1-ZQVb",
        "colab_type": "code",
        "outputId": "c8ab9de7-297e-489e-a833-1e3e70f9b5dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import asyncio\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "import aiohttp\n",
        "import cv2\n",
        "import websockets\n",
        "import socket\n",
        "from av import VideoFrame\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import dlib\n",
        "\n",
        "from aiortc import (RTCIceCandidate, RTCPeerConnection, RTCSessionDescription,\n",
        "                    VideoStreamTrack)\n",
        "from aiortc.contrib.media import MediaBlackhole, MediaPlayer, MediaRecorder\n",
        "from aiortc.contrib.signaling import object_from_string, object_to_string\n",
        "\n",
        "ROOT = os.path.dirname('.')\n",
        "print(ROOT)\n",
        "PHOTO_PATH = os.path.join(ROOT, 'photo.jpg')\n",
        "\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
        "\n",
        "def create_blank(width, height, rgb_color=(0, 0, 0)):\n",
        "    \"\"\"Create new image(numpy array) filled with certain color in RGB\"\"\"\n",
        "    # Create black blank image\n",
        "    image = np.zeros((height, width, 3), np.uint8)\n",
        "\n",
        "    # Since OpenCV uses BGR, convert the color first\n",
        "    color = tuple(reversed(rgb_color))\n",
        "    # Fill image with color\n",
        "    image[:] = color\n",
        "\n",
        "    return image\n",
        "\n",
        "black = (0, 0, 0)\n",
        "\n",
        "def draw_str(dst, target, s):\n",
        "    x, y = target\n",
        "    cv2.putText(dst, s, (x+1, y+1), cv2.FONT_HERSHEY_PLAIN, 1.0, (0, 0, 0), thickness = 2, lineType=cv2.LINE_AA)\n",
        "    cv2.putText(dst, s, (x, y), cv2.FONT_HERSHEY_PLAIN, 1.0, (255, 255, 255), lineType=cv2.LINE_AA)\n",
        "    \n",
        "class ApprtcSignaling:\n",
        "    def __init__(self, room):\n",
        "        self._http = None\n",
        "        self._origin = 'https://appr.tc'\n",
        "        self._room = room\n",
        "        self._websocket = None\n",
        "\n",
        "    async def connect(self):\n",
        "        join_url = self._origin + '/join/' + self._room\n",
        "\n",
        "        # fetch room parameters\n",
        "        self._http = aiohttp.ClientSession()\n",
        "        async with self._http.post(join_url) as response:\n",
        "            # we cannot use response.json() due to:\n",
        "            # https://github.com/webrtc/apprtc/issues/562\n",
        "            data = json.loads(await response.text())\n",
        "        assert data['result'] == 'SUCCESS'\n",
        "        params = data['params']\n",
        "\n",
        "        self.__is_initiator = params['is_initiator'] == 'true'\n",
        "        self.__messages = params['messages']\n",
        "        self.__post_url = self._origin + '/message/' + self._room + '/' + params['client_id']\n",
        "\n",
        "        # connect to websocket\n",
        "        self._websocket = await websockets.connect(params['wss_url'], extra_headers={\n",
        "            'Origin': self._origin\n",
        "        })\n",
        "        await self._websocket.send(json.dumps({\n",
        "            'clientid': params['client_id'],\n",
        "            'cmd': 'register',\n",
        "            'roomid': params['room_id'],\n",
        "        }))\n",
        "\n",
        "        return params\n",
        "\n",
        "    async def close(self):\n",
        "        if self._websocket:\n",
        "            await self.send(None)\n",
        "            self._websocket.close()\n",
        "        if self._http:\n",
        "            await self._http.close()\n",
        "\n",
        "    async def receive(self):\n",
        "        if self.__messages:\n",
        "            message = self.__messages.pop(0)\n",
        "        else:\n",
        "            message = await self._websocket.recv()\n",
        "            message = json.loads(message)['msg']\n",
        "        print('<', message)\n",
        "        return object_from_string(message)\n",
        "\n",
        "    async def send(self, obj):\n",
        "        message = object_to_string(obj)\n",
        "        print('>', message)\n",
        "        if self.__is_initiator:\n",
        "            await self._http.post(self.__post_url, data=message)\n",
        "        else:\n",
        "            await self._websocket.send(json.dumps({\n",
        "                'cmd': 'send',\n",
        "                'msg': message,\n",
        "            }))\n",
        "\n",
        "class VideoTransformTrack(VideoStreamTrack):\n",
        "    def __init__(self, track, transform):\n",
        "        super().__init__()  # don't forget this!\n",
        "        self.counter = 0\n",
        "        self.track = track\n",
        "        self.transform = transform\n",
        "        self.skip_frames = 30*3\n",
        "        self.frameCnt = 0\n",
        "        self.prevFrameCnt = 0\n",
        "        self.prevTime = datetime.now()\n",
        "        self.fpsValue = 0\n",
        "        self.previous_grey = None\n",
        "        self.hsv = None\n",
        "\n",
        "    async def recv(self):\n",
        "        global detector,predictor\n",
        "        frame = await self.track.recv()\n",
        "        self.counter = self.counter + 1\n",
        "\n",
        "        #print(\"frameCnt\",self.frameCnt)\n",
        "        \n",
        "        try:\n",
        "          \n",
        "          startTime =  datetime.now()\n",
        "\n",
        "          self.frameCnt=self.frameCnt+1\n",
        "\n",
        "          img = frame.to_ndarray(format='bgr24')\n",
        "          \n",
        "          height,width,depth = img.shape\n",
        "          if height > 480*2:\n",
        "            img = cv2.resize(img,(width//2,height//2))\n",
        "          elif height > 480*4:\n",
        "            img = cv2.resize(img,(width//4,height//4))\n",
        "          \n",
        "          height,width,depth = img.shape\n",
        "\n",
        "          tracks = []\n",
        "\n",
        "          if self.transform == 'cartoon':\n",
        "\n",
        "              # prepare color\n",
        "              img_color = cv2.pyrDown(cv2.pyrDown(img))\n",
        "              for _ in range(6):\n",
        "                  img_color = cv2.bilateralFilter(img_color, 9, 9, 7)\n",
        "              img_color = cv2.pyrUp(cv2.pyrUp(img_color))\n",
        "\n",
        "              # prepare edges\n",
        "              img_edges = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "              img_edges = cv2.adaptiveThreshold(\n",
        "                  cv2.medianBlur(img_edges, 7), 255,\n",
        "                  cv2.ADAPTIVE_THRESH_MEAN_C,\n",
        "                  cv2.THRESH_BINARY, 9, 2)\n",
        "              img_edges = cv2.cvtColor(img_edges, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "              # combine color and edges\n",
        "              img = cv2.bitwise_and(img_color, img_edges)\n",
        "\n",
        "          elif self.transform == 'face-landmarks':           \n",
        "\n",
        "              img = frame.to_ndarray(format='bgr24')\n",
        "\n",
        "              gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "              faces = detector(gray)\n",
        "              for face in faces:\n",
        "                  x1 = face.left()\n",
        "                  y1 = face.top()\n",
        "                  x2 = face.right()\n",
        "                  y2 = face.bottom()\n",
        "                  #cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "\n",
        "                  landmarks = predictor(gray, face)\n",
        "\n",
        "                  for n in range(0, 68):\n",
        "                      x = landmarks.part(n).x\n",
        "                      y = landmarks.part(n).y\n",
        "                      cv2.circle(img, (x, y), 4, (255, 0, 0), -1)\n",
        "\n",
        "          elif self.transform == 'detect-color':           \n",
        "                #blurred_frame = cv2.GaussianBlur(img, (5, 5), 0)\n",
        "                hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "  #               low_red = np.array([161, 155, 84])\n",
        "  #               high_red = np.array([179, 255, 255])\n",
        "  #               red_mask = cv2.inRange(hsv, low_red, high_red)\n",
        "\n",
        "  #               new_img = cv2.bitwise_and(img, img, mask=red_mask)\n",
        "                # Every color except white\n",
        "                low = np.array([0, 42, 0])\n",
        "                high = np.array([179, 255, 255])\n",
        "                mask = cv2.inRange(hsv, low, high)\n",
        "                new_img = cv2.bitwise_and(img, img, mask=mask)\n",
        "                img = new_image\n",
        "\n",
        "          elif self.transform == 'contours':           \n",
        "                blurred_frame = cv2.GaussianBlur(img, (5, 5), 0)\n",
        "                hsv = cv2.cvtColor(blurred_frame, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "  #               lower_blue = np.array([38, 86, 0])\n",
        "  #               upper_blue = np.array([121, 255, 255])\n",
        "  #               mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
        "\n",
        "                low_red = np.array([161, 155, 84])\n",
        "                high_red = np.array([179, 255, 255])\n",
        "                mask = cv2.inRange(hsv_frame, low_red, high_red)\n",
        "\n",
        "                _, contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
        "\n",
        "                tracks = contours\n",
        "\n",
        "                for contour in contours:\n",
        "                  area = cv2.contourArea(contour)\n",
        "                  if area > 500:\n",
        "                    cv2.drawContours(img, contour, -1, (0, 255, 0), 3)\n",
        "\n",
        "          elif self.transform == 'dense-of':\n",
        "              if self.previous_grey is None:\n",
        "                self.previous_grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                self.hsv = np.zeros_like(img)\n",
        "                self.hsv[...,1] = 255\n",
        "              else:\n",
        "                next = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "                img1 = img.copy()\n",
        "                img1r = cv2.resize(img1,(width//4,height//4))\n",
        "                self.previous_grey,img = drawDenseOpticalFlow(self.previous_grey,next,self.hsv)\n",
        "                img[30:30+height//4, width//2-width//8:width//2+width//8] = img1r\n",
        "              \n",
        "          elif self.transform == 'fast': #'sift':\n",
        "              traks, img = drawFAST(img) #drawSIFT(img)\n",
        "              \n",
        "          elif self.transform == 'orb':\n",
        "              # perform edge detection\n",
        "              gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "              #featuresDetector = cv2.xfeatures2d.SIFT_create()\n",
        "              #featuresDetector = cv2.xfeatures2d.SURF_create()\n",
        "              featuresDetector = cv2.ORB_create(nfeatures=1500)\n",
        "\n",
        "              keypoints, descriptors = featuresDetector.detectAndCompute(gray, None)\n",
        "\n",
        "              tracks = keypoints\n",
        "              \n",
        "              #img = create_blank(width, height, rgb_color=black)\n",
        "              \n",
        "              img = cv2.drawKeypoints(img, keypoints, None)  \n",
        "\n",
        "          elif self.transform == 'mean-shift':\n",
        "              # perform mean shift tracking\n",
        "              try:\n",
        "                if self.skip_fames>0:\n",
        "                  x = 200\n",
        "                  y = 205\n",
        "                  w = 100\n",
        "                  h = 115\n",
        "                  self.skip_fames=self.skip_fames-1\n",
        "                  if(self.skip_fames==0):\n",
        "                      roi = img[y: y + h, x: x + w]\n",
        "                      hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
        "                      roi_hist = cv2.calcHist([hsv_roi], [0], None, [180], [0, 180])\n",
        "                      roi_hist = cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
        "\n",
        "                      term_criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
        "                else:\n",
        "                    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "                    mask = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
        "\n",
        "                    _, track_window = cv2.meanShift(mask, (x, y, w, h), term_criteria)\n",
        "                    x, y, w, h = track_window\n",
        "\n",
        "              except:\n",
        "                pass\n",
        "\n",
        "              cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "          elif self.transform == 'edges':\n",
        "              # perform edge detection\n",
        "              img = cv2.cvtColor(cv2.Canny(img, 100, 200), cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "          elif self.transform == 'rotate':\n",
        "              # rotate image\n",
        "              rows, cols, _ = img.shape\n",
        "              M = cv2.getRotationMatrix2D((cols / 2, rows / 2), frame.time * 45, 1)\n",
        "              img = cv2.warpAffine(img, M, (cols, rows))\n",
        "          else:\n",
        "            return frame\n",
        "\n",
        "          endTime = datetime.now()\n",
        "          delta = (endTime-self.prevTime).total_seconds()\n",
        "          if delta>=1.0:\n",
        "              self.fpsValue = ((self.frameCnt-self.prevFrameCnt)/delta) \n",
        "              print(\"FPS = %3.2f, Frame = %6d, %0.4f sec, Track points = %5d\" % (self.fpsValue,self.frameCnt,(endTime - startTime).total_seconds(),len(tracks)))\n",
        "              self.prevTime = endTime\n",
        "              self.prevFrameCnt=self.frameCnt        \n",
        "\n",
        "\n",
        "          draw_str(img, (20, 20), \"FPS = %3.2f, Frame = %6d, %0.4f sec, Track points = %5d\" % (self.fpsValue,self.frameCnt,(endTime - startTime).total_seconds(),len(tracks)))\n",
        "\n",
        "          if clientsocket is not None:\n",
        "            data = cv2.imencode('.jpg', img)[1].tobytes()\n",
        "            clientsocket.send(data)\n",
        "\n",
        "#           return None\n",
        "          new_frame = VideoFrame.from_ndarray(img, format='bgr24')\n",
        "          new_frame.pts = frame.pts\n",
        "          new_frame.time_base = frame.time_base\n",
        "          return new_frame\n",
        "        \n",
        "        except Exception as e:\n",
        "#           exc_type, exc_obj, exc_tb = sys.exc_info()\n",
        "#           fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
        "#           print(exc_type, fname, exc_tb.tb_lineno)\n",
        "          print('Error on line {}'.format(sys.exc_info()[-1].tb_lineno), type(e).__name__, e)\n",
        "          return frame\n",
        "        \n",
        "class VideoImageTrack(VideoStreamTrack):\n",
        "    \"\"\"\n",
        "    A video stream track that returns a rotating image.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()  # don't forget this!\n",
        "        self.img = cv2.imread(PHOTO_PATH, cv2.IMREAD_COLOR)\n",
        "\n",
        "    async def recv(self):\n",
        "        pts, time_base = await self.next_timestamp()\n",
        "\n",
        "        # rotate image\n",
        "        rows, cols, _ = self.img.shape\n",
        "        M = cv2.getRotationMatrix2D((cols / 2, rows / 2), int(pts * time_base * 45), 1)\n",
        "        img = cv2.warpAffine(self.img, M, (cols, rows))\n",
        "\n",
        "        # create video frame\n",
        "        A = VideoFrame.from_ndarray(img, format='bgr24')\n",
        "        frame.pts = pts\n",
        "        frame.time_base = time_base\n",
        "\n",
        "        return frame\n",
        "\n",
        "\n",
        "async def run(pc, player, recorder, signaling, transform):\n",
        "    def add_tracks():\n",
        "        \n",
        "      #if player and player.audio:\n",
        "      #    pc.addTrack(player.audio)\n",
        "\n",
        "      if player and player.video:\n",
        "          local_video = player.video\n",
        "          local_video = VideoTransformTrack(player.video, transform=transform)\n",
        "          #local_video = VideoTransformTrack(player.video, transform='cartoon')\n",
        "          pc.addTrack(local_video)\n",
        "      else:\n",
        "          pc.addTransceiver('video','sendrecv') #this is the trick to echo webcame back\n",
        "          #pc.addTrack(local_video) #VideoImageTrack())\n",
        "\n",
        "#     @pc.on('track')\n",
        "#     def on_track(track):\n",
        "#         print('Track %s received' % track.kind)\n",
        "#         recorder.addTrack(track)\n",
        "\n",
        "    @pc.on('track')\n",
        "    def on_track(track):\n",
        "        #log_info('Track %s received', track.kind)\n",
        "        print('Track %s received' % track.kind)\n",
        "        if track.kind == 'audio':\n",
        "            #pc.addTrack(player.audio)\n",
        "            recorder.addTrack(track)\n",
        "        elif track.kind == 'video':\n",
        "            if not(player and player.video):\n",
        "              remote_video = VideoTransformTrack(track, transform=transform)\n",
        "              #remote_video = VideoTransformTrack(track, transform='rotate')\n",
        "              pc.addTrack(remote_video)\n",
        "              recorder.addTrack(remote_video)\n",
        "\n",
        "        @track.on('ended')\n",
        "        async def on_ended():\n",
        "            #log_info('Track %s ended', track.kind)\n",
        "            await recorder.stop()\n",
        "\n",
        "\n",
        "    # connect to websocket and join\n",
        "    params = await signaling.connect()\n",
        "\n",
        "    if params['is_initiator'] == 'true':\n",
        "        # send offer\n",
        "        add_tracks()\n",
        "        await pc.setLocalDescription(await pc.createOffer())\n",
        "        await signaling.send(pc.localDescription)\n",
        "        print('Please point a browser at %s' % params['room_link'])\n",
        "\n",
        "    # consume signaling\n",
        "    while True:\n",
        "        obj = await signaling.receive()\n",
        "\n",
        "        if isinstance(obj, RTCSessionDescription):\n",
        "            await pc.setRemoteDescription(obj)\n",
        "            await recorder.start()\n",
        "\n",
        "            if obj.type == 'offer':\n",
        "                # send answer\n",
        "                add_tracks()\n",
        "                \n",
        "#                 print('Add processed_video track')\n",
        "#                 processed_video = VideoTransformTrack(pc.getSenders()[0].track, transform='edges')\n",
        "#                 pc.addTrack(processed_video) #VideoImageTrack())\n",
        "\n",
        "                await pc.setLocalDescription(await pc.createAnswer())\n",
        "                await signaling.send(pc.localDescription)\n",
        "        elif isinstance(obj, RTCIceCandidate):\n",
        "            pc.addIceCandidate(obj)\n",
        "        else:\n",
        "            print('Exiting')\n",
        "            break\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ftooZw_BoKlN",
        "colab_type": "code",
        "outputId": "afb12e28-d9b3-4bc0-c206-a22011115f21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "ip = input(\"Enter IP destination for streaming out: \")\n",
        "print(ip)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter IP destination for streaming out: 198.52.172.162\n",
            "198.52.172.162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "POW7kAcW5FU2",
        "colab_type": "code",
        "outputId": "eee934e4-e861-43b0-f9aa-cb7ba3648d43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 883
        }
      },
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "#     parser = argparse.ArgumentParser(description='AppRTC')\n",
        "#     parser.add_argument('room', nargs='?')\n",
        "#     parser.add_argument('--play-from', help='Read the media from a file and sent it.'),\n",
        "#     parser.add_argument('--record-to', help='Write received media to a file.'),\n",
        "#     parser.add_argument('--verbose', '-v', action='count')\n",
        "#     args = parser.parse_args()\n",
        "  \n",
        "  \n",
        "  # #on server run this command:\n",
        "  \n",
        "    # #ffplay -f mjpeg tcp://0.0.0.0:45654?listen\n",
        "    import pafy\n",
        "    \n",
        "    clientsocket = None\n",
        "    try:\n",
        "      clientsocket=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n",
        "      clientsocket.connect((ip,45654)) #the target ip is where the ffplay is listening\n",
        "    except:\n",
        "      clientsocket = None\n",
        "    \n",
        "    usePafy = True\n",
        "    #usePafy = False\n",
        "\n",
        "    videoUrl = 'https://youtu.be/uuQlMCMT71I'\n",
        "    #videoUrl='https://www.youtube.com/watch?v=-jJVi-UxL9Y'\n",
        "    \n",
        "    if not usePafy:\n",
        "      videoUrl = !youtube-dl -f 'bestvideo[height<900]' -g $videoUrl\n",
        "      #videoUrl = !youtube-dl -f 'bestvideo' -g $videoUrl\n",
        "  #     #videoUrl = 'uuQlMCMT71I'\n",
        "  #     #url = !youtube-dl -g -f 'bestvideo[height<=$maxHeight]' 'https://www.youtube.com/watch?v=$videoUrl'\n",
        "      videoUrl = videoUrl[0]\n",
        "    \n",
        "    if usePafy:\n",
        "      videoPafy = pafy.new(videoUrl)\n",
        "      #best = videoPafy.getbest(preftype=\"webm\")\n",
        "      best = videoPafy.getbest(preftype=\"mp4\")    \n",
        "      videoUrl = best.url\n",
        "\n",
        "#     videoUrl = 'http://techslides.com/demos/sample-videos/small.mp4'\n",
        "    print('videoUrl=',videoUrl)\n",
        "\n",
        "    args_room = None #\"test1234test1\"\n",
        "    args_play_from = None\n",
        "    args_play_from = 'video6.mp4'\n",
        "    args_play_from = 'colorbars.mp4'\n",
        "    args_play_from = 'video1.mp4'\n",
        "    args_play_from = videoUrl\n",
        "    #args_play_from = None\n",
        "    args_record_to = None\n",
        "    #args_record_to = '/content/video7.mp4'\n",
        "    \n",
        "    #transform='contours'\n",
        "    #transform='edges'\n",
        "    transform = 'face-landmarks'\n",
        "    transform='orb'\n",
        "    transform = 'fast'\n",
        "    transform = 'dense-of'\n",
        "    #transform='detect-color'\n",
        "    #transform='mean-shift'\n",
        "    \n",
        "    if not args_room:\n",
        "        args_room = ''.join([random.choice('0123456789') for x in range(10)])\n",
        "\n",
        "#     if args_verbose:\n",
        "#         logging.basicConfig(level=logging.DEBUG)\n",
        "\n",
        "     # create signaling and peer connection\n",
        "    signaling = ApprtcSignaling(args_room)\n",
        "    pc = RTCPeerConnection()\n",
        "\n",
        "    # create media source\n",
        "    if args_play_from:\n",
        "        player = MediaPlayer(args_play_from)\n",
        "    else:\n",
        "        player = None\n",
        "\n",
        "    # create media sink\n",
        "    if args_record_to:\n",
        "        recorder = MediaRecorder(args_record_to)\n",
        "    else:\n",
        "        recorder = MediaBlackhole()\n",
        "\n",
        "    # run event loop\n",
        "    loop = asyncio.get_event_loop()\n",
        "    try:\n",
        "        loop.run_until_complete(run(\n",
        "            pc=pc,\n",
        "            player=player,\n",
        "            recorder=recorder,\n",
        "            signaling=signaling,\n",
        "            transform=transform))\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "    finally:\n",
        "        # cleanup\n",
        "        loop.run_until_complete(recorder.stop())\n",
        "        loop.run_until_complete(signaling.close())\n",
        "        loop.run_until_complete(pc.close())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "videoUrl= https://r5---sn-qxoedn7e.googlevideo.com/videoplayback?source=youtube&mm=31%2C26&mn=sn-qxoedn7e%2Csn-a5meknl6&sparams=dur%2Cei%2Cid%2Cip%2Cipbits%2Citag%2Clmt%2Cmime%2Cmm%2Cmn%2Cms%2Cmv%2Cpl%2Cratebypass%2Crequiressl%2Csource%2Cexpire&mt=1553489791&ratebypass=yes&mv=m&pl=23&requiressl=yes&ms=au%2Conr&mime=video%2Fmp4&fvip=5&id=o-ALPk-xduI95TSDCYpDb_ynHNAK6DdpkMYWYNEucgJ6Wj&dur=431.449&ipbits=0&c=WEB&expire=1553511552&itag=22&ip=35.227.146.56&ei=IGCYXNikAtL0kgbSgKW4Ag&lmt=1520190910635676&key=yt6&signature=3D45B6C494EEC29E371AF94BC55D8052BAD6BA1A.091D8B07DB8F0E2764A2FD73E9971A6ADCEC7162\n",
            "> {\"sdp\": \"v=0\\r\\no=- 3762478754 3762478754 IN IP4 0.0.0.0\\r\\ns=-\\r\\nt=0 0\\r\\na=group:BUNDLE 0\\r\\na=msid-semantic:WMS *\\r\\nm=video 40011 UDP/TLS/RTP/SAVPF 97 98 99 100 101 102\\r\\nc=IN IP4 172.28.0.2\\r\\na=sendrecv\\r\\na=extmap:1 urn:ietf:params:rtp-hdrext:sdes:mid\\r\\na=extmap:2 http://www.webrtc.org/experiments/rtp-hdrext/abs-send-time\\r\\na=mid:0\\r\\na=msid:ab131ab4-d0a4-438e-b2dc-cd7ab82c6535 db6e0468-b776-44a2-ac08-9b574253461f\\r\\na=rtcp:9 IN IP4 0.0.0.0\\r\\na=rtcp-mux\\r\\na=ssrc-group:FID 4005915994 2214220456\\r\\na=ssrc:4005915994 cname:{58ed6a3b-ffe2-43f6-b429-96ef0b84bede}\\r\\na=ssrc:2214220456 cname:{58ed6a3b-ffe2-43f6-b429-96ef0b84bede}\\r\\na=rtpmap:97 VP8/90000\\r\\na=rtcp-fb:97 nack\\r\\na=rtcp-fb:97 nack pli\\r\\na=rtcp-fb:97 goog-remb\\r\\na=rtpmap:98 rtx/90000\\r\\na=fmtp:98 apt=97\\r\\na=rtpmap:99 H264/90000\\r\\na=rtcp-fb:99 nack\\r\\na=rtcp-fb:99 nack pli\\r\\na=rtcp-fb:99 goog-remb\\r\\na=fmtp:99 packetization-mode=1;level-asymmetry-allowed=1;profile-level-id=42001f\\r\\na=rtpmap:100 rtx/90000\\r\\na=fmtp:100 apt=99\\r\\na=rtpmap:101 H264/90000\\r\\na=rtcp-fb:101 nack\\r\\na=rtcp-fb:101 nack pli\\r\\na=rtcp-fb:101 goog-remb\\r\\na=fmtp:101 packetization-mode=1;level-asymmetry-allowed=1;profile-level-id=42e01f\\r\\na=rtpmap:102 rtx/90000\\r\\na=fmtp:102 apt=101\\r\\na=candidate:2c3861ece2b9f99cb197fab08d5d4b23 1 udp 2130706431 172.28.0.2 40011 typ host\\r\\na=candidate:99f3638c2f34e882e6700e159ef3db05 1 udp 1694498815 35.227.146.56 40011 typ srflx raddr 172.28.0.2 rport 40011\\r\\na=end-of-candidates\\r\\na=ice-ufrag:loSU\\r\\na=ice-pwd:fWaOprDr2QFUqC4JUlkkhU\\r\\na=fingerprint:sha-256 43:F1:BB:21:27:E6:FF:E6:20:DE:10:E1:80:80:41:5F:AF:07:0E:15:47:27:79:5A:73:B4:BB:C0:36:5C:2A:76\\r\\na=setup:actpass\\r\\n\", \"type\": \"offer\"}\n",
            "Please point a browser at https://appr.tc/r/6969237746\n",
            "< {\"sdp\":\"v=0\\r\\no=- 6239137196866829433 2 IN IP4 127.0.0.1\\r\\ns=-\\r\\nt=0 0\\r\\na=group:BUNDLE 0\\r\\na=msid-semantic: WMS gbVVuhheCv8uGZqwDRfKBYJToWncgRzBlw40\\r\\nm=video 9 UDP/TLS/RTP/SAVPF 97 98 99 100 101 102\\r\\nc=IN IP4 0.0.0.0\\r\\na=rtcp:9 IN IP4 0.0.0.0\\r\\na=ice-ufrag:0+aZ\\r\\na=ice-pwd:UttqFR6CRGzB9AkvHy13g6kt\\r\\na=ice-options:trickle\\r\\na=fingerprint:sha-256 CD:2F:20:60:50:2D:33:C7:A6:8C:E5:82:60:50:6E:BC:00:43:F4:25:1B:75:70:9A:A8:C5:BF:B4:BB:F7:80:8D\\r\\na=setup:active\\r\\na=mid:0\\r\\na=extmap:2 http://www.webrtc.org/experiments/rtp-hdrext/abs-send-time\\r\\na=sendrecv\\r\\na=rtcp-mux\\r\\na=rtpmap:97 VP8/90000\\r\\na=rtcp-fb:97 goog-remb\\r\\na=rtcp-fb:97 nack\\r\\na=rtcp-fb:97 nack pli\\r\\na=rtpmap:98 rtx/90000\\r\\na=fmtp:98 apt=97\\r\\na=rtpmap:99 H264/90000\\r\\na=rtcp-fb:99 goog-remb\\r\\na=rtcp-fb:99 nack\\r\\na=rtcp-fb:99 nack pli\\r\\na=fmtp:99 level-asymmetry-allowed=1;packetization-mode=1;profile-level-id=42001f\\r\\na=rtpmap:100 rtx/90000\\r\\na=fmtp:100 apt=99\\r\\na=rtpmap:101 H264/90000\\r\\na=rtcp-fb:101 goog-remb\\r\\na=rtcp-fb:101 nack\\r\\na=rtcp-fb:101 nack pli\\r\\na=fmtp:101 level-asymmetry-allowed=1;packetization-mode=1;profile-level-id=42e01f\\r\\na=rtpmap:102 rtx/90000\\r\\na=fmtp:102 apt=101\\r\\na=ssrc-group:FID 150005146 1145919382\\r\\na=ssrc:150005146 cname:LuTxNsu7TRadAixZ\\r\\na=ssrc:150005146 msid:gbVVuhheCv8uGZqwDRfKBYJToWncgRzBlw40 21c2c12d-68d1-4e35-a769-d859fe6b3280\\r\\na=ssrc:150005146 mslabel:gbVVuhheCv8uGZqwDRfKBYJToWncgRzBlw40\\r\\na=ssrc:150005146 label:21c2c12d-68d1-4e35-a769-d859fe6b3280\\r\\na=ssrc:1145919382 cname:LuTxNsu7TRadAixZ\\r\\na=ssrc:1145919382 msid:gbVVuhheCv8uGZqwDRfKBYJToWncgRzBlw40 21c2c12d-68d1-4e35-a769-d859fe6b3280\\r\\na=ssrc:1145919382 mslabel:gbVVuhheCv8uGZqwDRfKBYJToWncgRzBlw40\\r\\na=ssrc:1145919382 label:21c2c12d-68d1-4e35-a769-d859fe6b3280\\r\\n\",\"type\":\"answer\"}\n",
            "Track video received\n",
            "< {\"type\":\"candidate\",\"label\":0,\"id\":\"0\",\"candidate\":\"candidate:337499441 1 udp 2122260223 192.168.1.37 38174 typ host generation 0 ufrag 0+aZ network-id 1 network-cost 10\"}\n",
            "< {\"type\":\"candidate\",\"label\":0,\"id\":\"0\",\"candidate\":\"candidate:3792547045 1 udp 1686052607 198.52.172.162 38174 typ srflx raddr 192.168.1.37 rport 38174 generation 0 ufrag 0+aZ network-id 1 network-cost 10\"}\n",
            "< {\"type\":\"candidate\",\"label\":0,\"id\":\"0\",\"candidate\":\"candidate:1158742792 1 udp 41886207 173.194.196.87 30278 typ relay raddr 198.52.172.162 rport 38174 generation 0 ufrag 0+aZ network-id 1 network-cost 10\"}\n",
            "FPS = 0.30, Frame =      1, 0.0084 sec, Track points =     0\n",
            "FPS = 1.80, Frame =      3, 0.4113 sec, Track points =     0\n",
            "FPS = 2.05, Frame =      6, 0.4461 sec, Track points =     0\n",
            "FPS = 2.06, Frame =      9, 0.4557 sec, Track points =     0\n",
            "FPS = 2.12, Frame =     12, 0.4265 sec, Track points =     0\n",
            "FPS = 2.15, Frame =     15, 0.4339 sec, Track points =     0\n",
            "FPS = 2.17, Frame =     18, 0.4201 sec, Track points =     0\n",
            "FPS = 2.26, Frame =     21, 0.4025 sec, Track points =     0\n",
            "FPS = 2.22, Frame =     24, 0.4089 sec, Track points =     0\n",
            "FPS = 2.26, Frame =     27, 0.4151 sec, Track points =     0\n",
            "FPS = 2.28, Frame =     30, 0.4158 sec, Track points =     0\n",
            "FPS = 2.14, Frame =     33, 0.4263 sec, Track points =     0\n",
            "FPS = 2.15, Frame =     36, 0.4347 sec, Track points =     0\n",
            "FPS = 2.16, Frame =     39, 0.4260 sec, Track points =     0\n",
            "FPS = 2.15, Frame =     42, 0.4098 sec, Track points =     0\n",
            "FPS = 2.11, Frame =     45, 0.4253 sec, Track points =     0\n",
            "FPS = 2.13, Frame =     48, 0.4323 sec, Track points =     0\n",
            "FPS = 2.13, Frame =     51, 0.4453 sec, Track points =     0\n",
            "FPS = 2.15, Frame =     54, 0.4284 sec, Track points =     0\n",
            "FPS = 2.10, Frame =     57, 0.4375 sec, Track points =     0\n",
            "FPS = 2.00, Frame =     59, 0.4147 sec, Track points =     0\n",
            "FPS = 2.15, Frame =     62, 0.4174 sec, Track points =     0\n",
            "FPS = 2.19, Frame =     65, 0.4169 sec, Track points =     0\n",
            "FPS = 2.16, Frame =     68, 0.4289 sec, Track points =     0\n",
            "FPS = 2.18, Frame =     71, 0.4112 sec, Track points =     0\n",
            "FPS = 2.13, Frame =     74, 0.4129 sec, Track points =     0\n",
            "FPS = 2.12, Frame =     77, 0.4296 sec, Track points =     0\n",
            "FPS = 2.15, Frame =     80, 0.4298 sec, Track points =     0\n",
            "FPS = 2.15, Frame =     83, 0.4244 sec, Track points =     0\n",
            "FPS = 2.12, Frame =     86, 0.4120 sec, Track points =     0\n",
            "FPS = 2.13, Frame =     89, 0.4237 sec, Track points =     0\n",
            "FPS = 2.17, Frame =     92, 0.4143 sec, Track points =     0\n",
            "FPS = 2.20, Frame =     95, 0.4212 sec, Track points =     0\n",
            "FPS = 2.05, Frame =     98, 0.4348 sec, Track points =     0\n",
            "FPS = 1.99, Frame =    100, 0.4460 sec, Track points =     0\n",
            "FPS = 1.91, Frame =    102, 0.4909 sec, Track points =     0\n",
            "< {\"type\":\"bye\"}\n",
            "Exiting\n",
            "> {\"type\": \"bye\"}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3B4adX0TuNOv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dY5WP9zCuXFV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def drawSIFT(image):\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  #Create SIFT Feature Detector object \n",
        "  sift = cv2.SIFT() \n",
        "  sift = cv2.xfeatures2d.SIFT_create() \n",
        "  (keypoints, descs) = sift.detectAndCompute(gray, None) \n",
        "  #Detect key points #\n",
        "  keypoints = sift.detect(gray, None) \n",
        "  #print(\"Number of keypoints Detected: \", len(keypoints)) \n",
        "  # Draw rich key points on input image \n",
        "  image = cv2.drawKeypoints(image, keypoints, 0,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "  return image\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DzQkNwb-ZQVf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install opencv-contrib-python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oI0uCuiL3Ndo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DgF3ARcUZQVi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pylab\n",
        "import imageio\n",
        "import cv2, pafy\n",
        "\n",
        "url = \"https://www.youtube.com/watch?v=uuQlMCMT71I\"\n",
        "#url = \"https://www.youtube.com/watch?v=OHKAkhdQ6B4\"\n",
        "videoPafy = pafy.new(url)\n",
        "best = videoPafy.getbest(preftype=\"webm\")\n",
        "best = videoPafy.getbest(preftype=\"mp4\")\n",
        "\n",
        "#imageio.setUseCache(false)\n",
        "\n",
        "#on server run this command:\n",
        "#ffplay -f mjpeg tcp://0.0.0.0:45654?listen\n",
        "#clientsocket=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n",
        "#clientsocket.connect((ip,45654)) #the target ip is where the ffplay is listening\n",
        "\n",
        "#filename = 'http://techslides.com/demos/sample-videos/small.mp4'\n",
        "filename = best.url\n",
        "#vid = imageio.get_reader(filename,  'ffmpeg')\n",
        "nums = range(1,1000)\n",
        "\n",
        "cap = cv2.VideoCapture(filename)\n",
        "\n",
        "#for image in vid:\n",
        "#for i, image in enumerate(vid):\n",
        "for num in nums:\n",
        "    flag, image = cap.retrieve()   \n",
        "    #image = vid.reader.get_next_data()\n",
        "    #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    data = cv2.imencode('.jpg', gray)[1].tobytes()\n",
        "    #clientsocket.send(data)\n",
        "    fig = pylab.figure()\n",
        "    fig.suptitle('image #{}'.format(num), fontsize=20)\n",
        "    pylab.imshow(gray)\n",
        "    pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uW7jGGAC9Lrr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/abhiTronix/vidgear.git; cd vidgear; pip install ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_SWG7_yD_0HJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q -U youtube-dl && pip install -q -U pafy && pip install opencv-contrib-python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sFAZcbsastP4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "url = 'https://youtu.be/uuQlMCMT71I'\n",
        "videoUrl = !youtube-dl -f 'bestvideo[height<=480]' -g $url\n",
        "print('videoUrl=',videoUrl[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T9iwVfBGvIn_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm Dri*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RV2xVRRstP82",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp A* video1.mp4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wBTgMM4oCy96",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt update && apt install --fix-missing && apt-get install libgstreamer1.0-0 gstreamer1.0-plugins-base gstreamer1.0-plugins-good gstreamer1.0-plugins-bad gstreamer1.0-plugins-ugly gstreamer1.0-libav gstreamer1.0-doc gstreamer1.0-tools gstreamer1.0-x gstreamer1.0-alsa gstreamer1.0-gl gstreamer1.0-gtk3 gstreamer1.0-qt5 gstreamer1.0-pulseaudio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uu0DvWSC9vii",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ip = input(\"Enter IP destination for streaming out: \")\n",
        "print(ip)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rwCHzbzov6_n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pylab\n",
        "import imageio\n",
        "import cv2, pafy\n",
        "import socket\n",
        "\n",
        "url = \"https://www.youtube.com/watch?v=uuQlMCMT71I\"\n",
        "#url = \"https://www.youtube.com/watch?v=OHKAkhdQ6B4\"\n",
        "videoPafy = pafy.new(url)\n",
        "best = videoPafy.getbest(preftype=\"webm\")\n",
        "best = videoPafy.getbest(preftype=\"mp4\")\n",
        "\n",
        "#imageio.setUseCache(false)\n",
        "\n",
        "#on server run this command:\n",
        "#ffplay -f mjpeg tcp://0.0.0.0:45654?listen\n",
        "clientsocket=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n",
        "clientsocket.connect((ip,45654)) #the target ip is where the ffplay is listening\n",
        "\n",
        "#filename = 'http://techslides.com/demos/sample-videos/small.mp4'\n",
        "filename = best.url\n",
        "vid = imageio.get_reader(filename,  'ffmpeg')\n",
        "nums = range(1,1000)\n",
        "\n",
        "for image in vid:\n",
        "#for i, image in enumerate(vid):\n",
        "#for num in nums:\n",
        "    #image = vid.reader.get_next_data()\n",
        "    #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    data = cv2.imencode('.jpg', gray)[1].tobytes()\n",
        "    clientsocket.send(data)\n",
        "#     fig = pylab.figure()\n",
        "#     fig.suptitle('image #{}'.format(num), fontsize=20)\n",
        "#     pylab.imshow(gray)\n",
        "#pylab.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dbZeCy_h9CQZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import required libraries\n",
        "from vidgear.gears import CamGear\n",
        "import cv2\n",
        "import pafy\n",
        "\n",
        "import socket\n",
        "import time\n",
        "\n",
        "#on server run this command:\n",
        "#ffplay -f mjpeg tcp://0.0.0.0:45654?listen\n",
        "clientsocket=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n",
        "clientsocket.connect((ip,45654)) #the target ip is where the ffplay is listening\n",
        "\n",
        "url = \"https://www.youtube.com/watch?v=uuQlMCMT71I\"\n",
        "#url = \"https://www.youtube.com/watch?v=OHKAkhdQ6B4\"\n",
        "videoPafy = pafy.new(url)\n",
        "best = videoPafy.getbest(preftype=\"webm\")\n",
        "best = videoPafy.getbest(preftype=\"mp4\")\n",
        "\n",
        "print(best.url)\n",
        "stream = CamGear(source=best.url).start() \n",
        "# define various attributes and start the stream\n",
        "count = 1000\n",
        "# infinite loop\n",
        "while count>0:\n",
        "\tframe = stream.read()\n",
        "\tcount = count-1\n",
        "  # check if frame is None\n",
        "\tif frame is None:\n",
        "\t\t#if True break the infinite loop\n",
        "\t\tcontinue\n",
        "\n",
        "\tdata = cv2.imencode('.jpg', img)[1].tobytes()\n",
        "\tclientsocket.send(data)\n",
        "print(count)\n",
        "clientsocket.close()\n",
        "stream.stop()\n",
        "# safely close video stream."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x91YVR----vS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(cv2.getBuildInformation())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IDGeQDKLBaIH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install opencv-contrib-python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jt_XiVgkDqmZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}